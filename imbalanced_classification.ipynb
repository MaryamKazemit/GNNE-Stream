{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaryamKazemit/GNNE-Stream/blob/main/imbalanced_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJzdXgWsqw7t"
      },
      "source": [
        "# Imbalanced classification: credit card fraud detection\n",
        "\n",
        "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2019/05/28<br>\n",
        "**Last modified:** 2020/04/17<br>\n",
        "**Description:** Demonstration of how to handle highly imbalanced classification problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1Ds23XNqw7v"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This example looks at the\n",
        "[Kaggle Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud/)\n",
        "dataset to demonstrate how\n",
        "to train a classification model on data with highly imbalanced classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-1LU9bDqw7v"
      },
      "source": [
        "## First, vectorize the CSV data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "36u7W9j1LuON",
        "outputId": "18b1be07-52d0-49d3-eb57-fce10affb113",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G8rDhhZNqw7w",
        "outputId": "a5f8dacd-7c72-4e73-8553-657cfe58d764",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
            "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
            "features.shape: (284807, 30)\n",
            "targets.shape: (284807, 1)\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "# Get the real data from https://www.kaggle.com/mlg-ulb/creditcardfraud/\n",
        "fname = \"/content/drive/My Drive/creditcard.csv\"\n",
        "\n",
        "# loading data that can be easily done in pandas do it himself\n",
        "all_features = []\n",
        "all_targets = [] #save labels\n",
        "with open(fname) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i == 0:\n",
        "            print(\"HEADER:\", line.strip())\n",
        "            continue  # Skip header\n",
        "        # strip چیزهای زائد را بنداز مثل space اول و آخر\n",
        "        fields = line.strip().split(\",\")\n",
        "        # تمام ستون ها به جز ستون آخر\n",
        "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
        "        # ستون آخر که label داده ها بوده را در target بریز\n",
        "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
        "        if i == 1:\n",
        "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
        "\n",
        "features = np.array(all_features, dtype=\"float32\")\n",
        "targets = np.array(all_targets, dtype=\"uint8\")\n",
        "print(\"features.shape:\", features.shape)\n",
        "print(\"targets.shape:\", targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkBsAV8Iqw7w"
      },
      "source": [
        "## Prepare a validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_8ov3uBaqw7x",
        "outputId": "06770800-dab0-4c19-d073-38f5041624ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 227846\n",
            "Number of validation samples: 56961\n"
          ]
        }
      ],
      "source": [
        "# instead of doing validation test split with sci-kit learn did it himself\n",
        "# از اون 30 تایی ها چند تا ویژگی داری طولش را بگیر\n",
        "num_val_samples = int(len(features) * 0.2)\n",
        "# از ابتدا تا 0.2 آخر\n",
        "train_features = features[:-num_val_samples]\n",
        "train_targets = targets[:-num_val_samples]\n",
        "# از 0.2 آخر به بعد برای تست\n",
        "val_features = features[-num_val_samples:]\n",
        "val_targets = targets[-num_val_samples:]\n",
        "\n",
        "print(\"Number of training samples:\", len(train_features))\n",
        "print(\"Number of validation samples:\", len(val_features))\n",
        "# نسبت 80 به 20 دیتای train و test را جدا کرده"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMuJMtsZqw7x"
      },
      "source": [
        "## Analyze class imbalance in the targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pKsXjntzqw7y",
        "outputId": "61cb094a-e65a-401d-d9d5-188802e74cfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of positive samples in training data: 417 (0.18% of total)\n"
          ]
        }
      ],
      "source": [
        "# bincount() می شمارد کلاس صفر چندتا داریم؟یک چندتا داریم؟\n",
        "# 1=fraud 0=notfraud\n",
        "# fraction of data that was fraud to whole data: 100 * float(counts[1]) / len(train_targets)\n",
        "counts = np.bincount(train_targets[:, 0])\n",
        "print(\n",
        "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
        "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
        "    )\n",
        ")\n",
        "\n",
        "# due to binary\n",
        "weight_for_0 = 1.0 / counts[0]\n",
        "weight_for_1 = 1.0 / counts[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znbk6d-kqw7y"
      },
      "source": [
        "## Normalize the data using training set statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bhGD1SrJqw7y"
      },
      "outputs": [],
      "source": [
        "# normalized data himself instead of using sci-kitlearn\n",
        "mean = np.mean(train_features, axis=0)\n",
        "# make data zero-center\n",
        "train_features -= mean\n",
        "val_features -= mean\n",
        "# standard derivation\n",
        "std = np.std(train_features, axis=0)\n",
        "# دیتا میشه zero-center ای که به یک نسبت پخش شده در حول صفر و فشردگی و پخش در همه بعد ها یکسان است\n",
        "train_features /= std\n",
        "val_features /= std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnzSBA9wqw7y"
      },
      "source": [
        "## Build a binary classification model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N9VSkzm8qw7z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "8d99ba18-ec41-4380-d4f1-0f4b1fed4808"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m7,936\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m65,792\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m65,792\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m257\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,936</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m139,777\u001b[0m (546.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,777</span> (546.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m139,777\u001b[0m (546.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,777</span> (546.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import keras\n",
        "\n",
        "# can also write model = keras.Sequential() then model.add()\n",
        "# لایه ها را در ادامه با , از هم جدا کرده\n",
        "# here the layers are passed to constructor of sequential instead of adding\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        # train_features.shape[1:] یعنی number of samples*number of features که این یعنی تعداد feat ها که 30 است\n",
        "        keras.Input(shape=train_features.shape[1:]),\n",
        "        keras.layers.Dense(256, activation=\"relu\"),\n",
        "        keras.layers.Dense(256, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(256, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        # لایه آخر یه آره یا نه اضافه کرده\n",
        "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ozGPyxqw7z"
      },
      "source": [
        "## Train the model with `class_weight` argument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OdllW5xqqw7z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9e164d2-b645-4442-ee8a-00afc30a626f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "112/112 - 10s - 94ms/step - fn: 55.0000 - fp: 30202.0000 - loss: 2.4622e-06 - precision: 0.0118 - recall: 0.8681 - tn: 197227.0000 - tp: 362.0000 - val_fn: 10.0000 - val_fp: 824.0000 - val_loss: 0.0891 - val_precision: 0.0731 - val_recall: 0.8667 - val_tn: 56062.0000 - val_tp: 65.0000\n",
            "Epoch 2/30\n",
            "112/112 - 2s - 19ms/step - fn: 34.0000 - fp: 6667.0000 - loss: 1.3530e-06 - precision: 0.0543 - recall: 0.9185 - tn: 220762.0000 - tp: 383.0000 - val_fn: 6.0000 - val_fp: 2066.0000 - val_loss: 0.1174 - val_precision: 0.0323 - val_recall: 0.9200 - val_tn: 54820.0000 - val_tp: 69.0000\n",
            "Epoch 3/30\n",
            "112/112 - 0s - 4ms/step - fn: 30.0000 - fp: 9930.0000 - loss: 1.5505e-06 - precision: 0.0375 - recall: 0.9281 - tn: 217499.0000 - tp: 387.0000 - val_fn: 10.0000 - val_fp: 490.0000 - val_loss: 0.0828 - val_precision: 0.1171 - val_recall: 0.8667 - val_tn: 56396.0000 - val_tp: 65.0000\n",
            "Epoch 4/30\n",
            "112/112 - 0s - 4ms/step - fn: 29.0000 - fp: 6483.0000 - loss: 1.0603e-06 - precision: 0.0565 - recall: 0.9305 - tn: 220946.0000 - tp: 388.0000 - val_fn: 6.0000 - val_fp: 2313.0000 - val_loss: 0.1241 - val_precision: 0.0290 - val_recall: 0.9200 - val_tn: 54573.0000 - val_tp: 69.0000\n",
            "Epoch 5/30\n",
            "112/112 - 0s - 4ms/step - fn: 27.0000 - fp: 6799.0000 - loss: 1.0441e-06 - precision: 0.0542 - recall: 0.9353 - tn: 220630.0000 - tp: 390.0000 - val_fn: 8.0000 - val_fp: 675.0000 - val_loss: 0.0760 - val_precision: 0.0903 - val_recall: 0.8933 - val_tn: 56211.0000 - val_tp: 67.0000\n",
            "Epoch 6/30\n",
            "112/112 - 1s - 5ms/step - fn: 16.0000 - fp: 6892.0000 - loss: 7.7838e-07 - precision: 0.0550 - recall: 0.9616 - tn: 220537.0000 - tp: 401.0000 - val_fn: 13.0000 - val_fp: 124.0000 - val_loss: 0.0150 - val_precision: 0.3333 - val_recall: 0.8267 - val_tn: 56762.0000 - val_tp: 62.0000\n",
            "Epoch 7/30\n",
            "112/112 - 1s - 5ms/step - fn: 17.0000 - fp: 7131.0000 - loss: 7.8091e-07 - precision: 0.0531 - recall: 0.9592 - tn: 220298.0000 - tp: 400.0000 - val_fn: 8.0000 - val_fp: 628.0000 - val_loss: 0.0564 - val_precision: 0.0964 - val_recall: 0.8933 - val_tn: 56258.0000 - val_tp: 67.0000\n",
            "Epoch 8/30\n",
            "112/112 - 0s - 4ms/step - fn: 18.0000 - fp: 8549.0000 - loss: 1.0386e-06 - precision: 0.0446 - recall: 0.9568 - tn: 218880.0000 - tp: 399.0000 - val_fn: 9.0000 - val_fp: 904.0000 - val_loss: 0.0497 - val_precision: 0.0680 - val_recall: 0.8800 - val_tn: 55982.0000 - val_tp: 66.0000\n",
            "Epoch 9/30\n",
            "112/112 - 0s - 4ms/step - fn: 13.0000 - fp: 6768.0000 - loss: 6.9959e-07 - precision: 0.0563 - recall: 0.9688 - tn: 220661.0000 - tp: 404.0000 - val_fn: 6.0000 - val_fp: 4338.0000 - val_loss: 0.1973 - val_precision: 0.0157 - val_recall: 0.9200 - val_tn: 52548.0000 - val_tp: 69.0000\n",
            "Epoch 10/30\n",
            "112/112 - 1s - 5ms/step - fn: 17.0000 - fp: 8236.0000 - loss: 9.8300e-07 - precision: 0.0463 - recall: 0.9592 - tn: 219193.0000 - tp: 400.0000 - val_fn: 9.0000 - val_fp: 377.0000 - val_loss: 0.0324 - val_precision: 0.1490 - val_recall: 0.8800 - val_tn: 56509.0000 - val_tp: 66.0000\n",
            "Epoch 11/30\n",
            "112/112 - 1s - 5ms/step - fn: 15.0000 - fp: 5871.0000 - loss: 6.0106e-07 - precision: 0.0641 - recall: 0.9640 - tn: 221558.0000 - tp: 402.0000 - val_fn: 8.0000 - val_fp: 2567.0000 - val_loss: 0.0970 - val_precision: 0.0254 - val_recall: 0.8933 - val_tn: 54319.0000 - val_tp: 67.0000\n",
            "Epoch 12/30\n",
            "112/112 - 1s - 8ms/step - fn: 7.0000 - fp: 4851.0000 - loss: 4.6622e-07 - precision: 0.0779 - recall: 0.9832 - tn: 222578.0000 - tp: 410.0000 - val_fn: 9.0000 - val_fp: 435.0000 - val_loss: 0.0248 - val_precision: 0.1317 - val_recall: 0.8800 - val_tn: 56451.0000 - val_tp: 66.0000\n",
            "Epoch 13/30\n",
            "112/112 - 1s - 6ms/step - fn: 11.0000 - fp: 5649.0000 - loss: 5.1827e-07 - precision: 0.0671 - recall: 0.9736 - tn: 221780.0000 - tp: 406.0000 - val_fn: 8.0000 - val_fp: 1021.0000 - val_loss: 0.0489 - val_precision: 0.0616 - val_recall: 0.8933 - val_tn: 55865.0000 - val_tp: 67.0000\n",
            "Epoch 14/30\n",
            "112/112 - 1s - 6ms/step - fn: 7.0000 - fp: 5196.0000 - loss: 4.7190e-07 - precision: 0.0731 - recall: 0.9832 - tn: 222233.0000 - tp: 410.0000 - val_fn: 8.0000 - val_fp: 524.0000 - val_loss: 0.0285 - val_precision: 0.1134 - val_recall: 0.8933 - val_tn: 56362.0000 - val_tp: 67.0000\n",
            "Epoch 15/30\n",
            "112/112 - 1s - 6ms/step - fn: 7.0000 - fp: 4381.0000 - loss: 4.1882e-07 - precision: 0.0856 - recall: 0.9832 - tn: 223048.0000 - tp: 410.0000 - val_fn: 9.0000 - val_fp: 421.0000 - val_loss: 0.0225 - val_precision: 0.1355 - val_recall: 0.8800 - val_tn: 56465.0000 - val_tp: 66.0000\n",
            "Epoch 16/30\n",
            "112/112 - 1s - 6ms/step - fn: 9.0000 - fp: 6045.0000 - loss: 5.5484e-07 - precision: 0.0632 - recall: 0.9784 - tn: 221384.0000 - tp: 408.0000 - val_fn: 6.0000 - val_fp: 2445.0000 - val_loss: 0.1152 - val_precision: 0.0274 - val_recall: 0.9200 - val_tn: 54441.0000 - val_tp: 69.0000\n",
            "Epoch 17/30\n",
            "112/112 - 0s - 4ms/step - fn: 7.0000 - fp: 7546.0000 - loss: 6.5760e-07 - precision: 0.0515 - recall: 0.9832 - tn: 219883.0000 - tp: 410.0000 - val_fn: 8.0000 - val_fp: 1439.0000 - val_loss: 0.0624 - val_precision: 0.0445 - val_recall: 0.8933 - val_tn: 55447.0000 - val_tp: 67.0000\n",
            "Epoch 18/30\n",
            "112/112 - 1s - 6ms/step - fn: 8.0000 - fp: 3583.0000 - loss: 3.5819e-07 - precision: 0.1025 - recall: 0.9808 - tn: 223846.0000 - tp: 409.0000 - val_fn: 12.0000 - val_fp: 230.0000 - val_loss: 0.0116 - val_precision: 0.2150 - val_recall: 0.8400 - val_tn: 56656.0000 - val_tp: 63.0000\n",
            "Epoch 19/30\n",
            "112/112 - 1s - 5ms/step - fn: 4.0000 - fp: 4523.0000 - loss: 4.3593e-07 - precision: 0.0837 - recall: 0.9904 - tn: 222906.0000 - tp: 413.0000 - val_fn: 8.0000 - val_fp: 414.0000 - val_loss: 0.0182 - val_precision: 0.1393 - val_recall: 0.8933 - val_tn: 56472.0000 - val_tp: 67.0000\n",
            "Epoch 20/30\n",
            "112/112 - 1s - 6ms/step - fn: 3.0000 - fp: 3197.0000 - loss: 2.7722e-07 - precision: 0.1146 - recall: 0.9928 - tn: 224232.0000 - tp: 414.0000 - val_fn: 10.0000 - val_fp: 285.0000 - val_loss: 0.0187 - val_precision: 0.1857 - val_recall: 0.8667 - val_tn: 56601.0000 - val_tp: 65.0000\n",
            "Epoch 21/30\n",
            "112/112 - 0s - 4ms/step - fn: 3.0000 - fp: 5752.0000 - loss: 5.1994e-07 - precision: 0.0671 - recall: 0.9928 - tn: 221677.0000 - tp: 414.0000 - val_fn: 8.0000 - val_fp: 747.0000 - val_loss: 0.0343 - val_precision: 0.0823 - val_recall: 0.8933 - val_tn: 56139.0000 - val_tp: 67.0000\n",
            "Epoch 22/30\n",
            "112/112 - 1s - 5ms/step - fn: 6.0000 - fp: 4947.0000 - loss: 4.7768e-07 - precision: 0.0767 - recall: 0.9856 - tn: 222482.0000 - tp: 411.0000 - val_fn: 5.0000 - val_fp: 1769.0000 - val_loss: 0.0732 - val_precision: 0.0381 - val_recall: 0.9333 - val_tn: 55117.0000 - val_tp: 70.0000\n",
            "Epoch 23/30\n",
            "112/112 - 1s - 5ms/step - fn: 8.0000 - fp: 4457.0000 - loss: 3.8397e-07 - precision: 0.0841 - recall: 0.9808 - tn: 222972.0000 - tp: 409.0000 - val_fn: 8.0000 - val_fp: 950.0000 - val_loss: 0.0415 - val_precision: 0.0659 - val_recall: 0.8933 - val_tn: 55936.0000 - val_tp: 67.0000\n",
            "Epoch 24/30\n",
            "112/112 - 0s - 4ms/step - fn: 5.0000 - fp: 4523.0000 - loss: 3.6908e-07 - precision: 0.0835 - recall: 0.9880 - tn: 222906.0000 - tp: 412.0000 - val_fn: 9.0000 - val_fp: 563.0000 - val_loss: 0.0243 - val_precision: 0.1049 - val_recall: 0.8800 - val_tn: 56323.0000 - val_tp: 66.0000\n",
            "Epoch 25/30\n",
            "112/112 - 1s - 6ms/step - fn: 3.0000 - fp: 3557.0000 - loss: 3.1233e-07 - precision: 0.1043 - recall: 0.9928 - tn: 223872.0000 - tp: 414.0000 - val_fn: 9.0000 - val_fp: 1134.0000 - val_loss: 0.0469 - val_precision: 0.0550 - val_recall: 0.8800 - val_tn: 55752.0000 - val_tp: 66.0000\n",
            "Epoch 26/30\n",
            "112/112 - 1s - 5ms/step - fn: 2.0000 - fp: 3288.0000 - loss: 2.7601e-07 - precision: 0.1121 - recall: 0.9952 - tn: 224141.0000 - tp: 415.0000 - val_fn: 11.0000 - val_fp: 322.0000 - val_loss: 0.0168 - val_precision: 0.1658 - val_recall: 0.8533 - val_tn: 56564.0000 - val_tp: 64.0000\n",
            "Epoch 27/30\n",
            "112/112 - 1s - 5ms/step - fn: 4.0000 - fp: 2496.0000 - loss: 2.4125e-07 - precision: 0.1420 - recall: 0.9904 - tn: 224933.0000 - tp: 413.0000 - val_fn: 9.0000 - val_fp: 779.0000 - val_loss: 0.0341 - val_precision: 0.0781 - val_recall: 0.8800 - val_tn: 56107.0000 - val_tp: 66.0000\n",
            "Epoch 28/30\n",
            "112/112 - 0s - 4ms/step - fn: 1.0000 - fp: 2868.0000 - loss: 2.2241e-07 - precision: 0.1267 - recall: 0.9976 - tn: 224561.0000 - tp: 416.0000 - val_fn: 12.0000 - val_fp: 188.0000 - val_loss: 0.0102 - val_precision: 0.2510 - val_recall: 0.8400 - val_tn: 56698.0000 - val_tp: 63.0000\n",
            "Epoch 29/30\n",
            "112/112 - 1s - 6ms/step - fn: 0.0000e+00 - fp: 1727.0000 - loss: 1.5662e-07 - precision: 0.1945 - recall: 1.0000 - tn: 225702.0000 - tp: 417.0000 - val_fn: 11.0000 - val_fp: 342.0000 - val_loss: 0.0181 - val_precision: 0.1576 - val_recall: 0.8533 - val_tn: 56544.0000 - val_tp: 64.0000\n",
            "Epoch 30/30\n",
            "112/112 - 0s - 4ms/step - fn: 3.0000 - fp: 3642.0000 - loss: 3.1203e-07 - precision: 0.1021 - recall: 0.9928 - tn: 223787.0000 - tp: 414.0000 - val_fn: 10.0000 - val_fp: 651.0000 - val_loss: 0.0336 - val_precision: 0.0908 - val_recall: 0.8667 - val_tn: 56235.0000 - val_tp: 65.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d9a5c8bb0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "metrics = [\n",
        "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "    keras.metrics.FalsePositives(name=\"fp\"),\n",
        "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "    keras.metrics.TruePositives(name=\"tp\"),\n",
        "    keras.metrics.Precision(name=\"precision\"),\n",
        "    keras.metrics.Recall(name=\"recall\"),\n",
        "]\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
        ")\n",
        "# to save the model(for more info: https://aparat.com/v/r879wf1?playlist=342711)\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.keras\")]\n",
        "# this should be from dictionary type so {}\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "model.fit(\n",
        "    train_features,\n",
        "    train_targets,\n",
        "    batch_size=2048,\n",
        "    epochs=30,\n",
        "    verbose=2,\n",
        "    # this was optional\n",
        "    callbacks=callbacks,\n",
        "    validation_data=(val_features, val_targets),\n",
        "    # penalize according to samples\n",
        "    class_weight=class_weight,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UslxzTUJqw7z"
      },
      "source": [
        "## Conclusions\n",
        "\n",
        "At the end of training, out of 56,961 validation transactions, we are:\n",
        "\n",
        "- Correctly identifying 66 of them as fraudulent\n",
        "- Missing 9 fraudulent transactions\n",
        "- At the cost of incorrectly flagging 441 legitimate transactions\n",
        "\n",
        "In the real world, one would put an even higher weight on class 1,\n",
        "so as to reflect that False Negatives are more costly than False Positives.\n",
        "\n",
        "Next time your credit card gets  declined in an online purchase -- this is why.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}